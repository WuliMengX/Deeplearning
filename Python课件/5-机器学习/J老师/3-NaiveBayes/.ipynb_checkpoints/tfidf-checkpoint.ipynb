{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立tf-idf词频权重矩阵:将词转为词向量\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(norm='l2',ngram_range=(1,2))\n",
    "tf_train_data = tfidf.fit_transform(train_content)\n",
    "tf_valid_data = tfidf.transform(valid_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"朴素贝叶斯模型\"\"\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(tf_train_data, train_label)\n",
    "\n",
    "print(NB_model.score(tf_valid_data,valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.656 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "documents = [\n",
    "    \"低头亲吻我的左手\",  # 文档 1\n",
    "    \"换取被宽恕的承诺\",  # 文档 2\n",
    "    \"老旧管风琴在角落\",  # 文档 3\n",
    "    \"一直一直一直伴奏\",  # 文档 4\n",
    "]\n",
    "documents = [\" \".join(jieba.cut(item)) for item in documents]\n",
    "# ['低头 亲吻 我 的 左手', \n",
    "#  '换取 被 宽恕 的 承诺', \n",
    "#  '老旧 管风琴 在 角落', \n",
    "#  '一直 一直 一直 伴奏']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['低头 亲吻 我 的 左手', '换取 被 宽恕 的 承诺', '老旧 管风琴 在 角落', '一直 一直 一直 伴奏']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingtu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(norm=None)\n",
    "train = [\"Chinese Beijing Chinese\", #文档一\n",
    "        \"Chinese Chinese Shanghai\",  #文档二\n",
    "        \"Chinese Macao\",  #文档三\n",
    "        \"Tokyo Japan Chinese\"]  #文档四\n",
    "# 训练，构建词汇表以及词项idf值，并将输入文本列表转成VSM矩阵形式\n",
    "tv_fit = tv.fit_transform(train)\n",
    "# 查看一下构建的词汇表\n",
    "tv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beijing:1*(log((4+1)/(1+1))+1)\n",
    "#chinese:2*(log(4+1)/(4+1) + 1) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91629073, 2.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 2.        , 0.        , 0.        , 1.91629073,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , 1.91629073, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 1.91629073, 0.        , 0.        ,\n",
       "        1.91629073]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看输入文本列表的VSM矩阵\n",
    "tv_fit.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词语beijing的在第1篇文本中的频次为 tf(beijing,d1)=1.0\n",
    "词语beijing只在第1篇文本中出现过df(d,beijing)=1,nd=4,\n",
    "代入平滑版的tf-idf计算式得到1.9\n",
    "1.0*(1+log((4+1)/(1+1)))\n",
    "1.916290731874155\n",
    "词语chinese的在第1篇文本中的频次为2.0，tf(chinese,d1)=2.0\n",
    "词语chinese只在4篇文本中都出现过df(d,beijing)=4,nd=4,\n",
    "代入平滑版的tf-idf计算式得到2.0\n",
    "2.0*(1+log(4+1/4+1))\n",
    "2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 3.        , 1.91629073, 0.        , 0.        ,\n",
       "        1.91629073]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"Chinese Chinese Chinese Tokyo Japan\"]\n",
    "#test_fit = tv.transform(test)\n",
    "#print(tv.get_feature_names())\n",
    "#test_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chinese词项在测试文本中出现了3次，因此tf(chinese,t)=3\n",
    "# 从训练集知道chinese在4篇文本中都出现，因此idf(d,beijing)=4,nd=4\n",
    "# 计算得到tf-idf值 文档总数4 / chinese出现过的次数4 log(4/4)\n",
    "3.0*(1+log((4+1)/(4+1))) #sklean中过度考虑了分子和分母可能为0情况所以+1\n",
    "3.0\n",
    "# japan词项在测试文本中出现了1次，因此tf(japan,t)=1\n",
    "# 从训练集知道japan仅在第4篇文本中出现，因此df(d,japan)=1,nd=4\n",
    "# 计算得到文本的tf-idf值\n",
    "1.0*(1+log((4+1)/(1+1)))\n",
    "1.916290731874155"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
